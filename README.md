# ğŸ™ï¸ ChatGPT Voice Assistant

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![OpenAI](https://img.shields.io/badge/OpenAI-API-green)
![Status](https://img.shields.io/badge/Status-DidÃ¡tico-orange)

Este projeto Ã© um assistente de voz que integra **Whisper (OpenAI)** para transcriÃ§Ã£o de Ã¡udio, **ChatGPT** para geraÃ§Ã£o de respostas inteligentes e **gTTS/Pygame** para sÃ­ntese e reproduÃ§Ã£o de voz.

O objetivo Ã© demonstrar a orquestraÃ§Ã£o de diferentes mÃ³dulos em Python para criar uma interface de conversaÃ§Ã£o natural.

## ğŸš€ Tecnologias Utilizadas

- **[Python](https://www.python.org/)**: Linguagem principal.
- **[OpenAI Whisper](https://openai.com/research/whisper)**: Para converter fala em texto (Speech-to-Text).
- **[OpenAI GPT](https://platform.openai.com/)**: Modelo de linguagem para gerar respostas.
- **[gTTS (Google Text-to-Speech)](https://pypi.org/project/gTTS/)**: Para converter texto em Ã¡udio.
- **[Pygame](https://www.pygame.org/)**: Para reproduÃ§Ã£o do Ã¡udio gerado.
- **Python-dotenv**: Gerenciamento seguro de chaves de API.

## ğŸ“‚ Estrutura do Projeto

```plaintext
chatgpt-voice-assistant/
â”‚
â”œâ”€â”€ app.py                # Orquestrador (Main)
â”œâ”€â”€ speech_to_text.py     # MÃ³dulo de transcriÃ§Ã£o (Whisper)
â”œâ”€â”€ chat_response.py      # MÃ³dulo de inteligÃªncia (GPT)
â”œâ”€â”€ text_to_speech.py     # MÃ³dulo de sÃ­ntese de voz (gTTS)
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â”œâ”€â”€ .env                  # Chave da API (NÃ£o versionado)
â””â”€â”€ entrada.wav           # Arquivo de Ã¡udio para teste

## ğŸ”„ Fluxo de Dados

```mermaid
graph TD;
    A[ğŸ¤ entrada.wav] -->|Whisper| B(speech_to_text.py);
    B -->|Texto Transcrito| C(chat_response.py);
    C -->|Consulta GPT| D{OpenAI API};
    D -->|Resposta Texto| C;
    C -->|Texto| E(text_to_speech.py);
    E -->|gTTS| F[ğŸ”Š ReproduÃ§Ã£o Pygame];

    âš™ï¸ ConfiguraÃ§Ã£o
1. PrÃ©-requisitos
No Codespaces ou Linux, Ã© recomendÃ¡vel instalar o ffmpeg para manipulaÃ§Ã£o de Ã¡udio:

Bash

sudo apt update && sudo apt install -y ffmpeg    

2. VariÃ¡veis de Ambiente
Crie um arquivo .env na raiz do projeto e adicione sua chave da OpenAI:

Snippet de cÃ³digo

OPENAI_API_KEY=sk-sua-chave-aqui-xyz...

âš ï¸ AtenÃ§Ã£o: Este projeto utiliza a API da OpenAI. Ã‰ necessÃ¡rio ter crÃ©ditos ativos na plataforma (Billing) para que a transcriÃ§Ã£o e a geraÃ§Ã£o de texto funcionem corretamente.

ğŸ“¦ InstalaÃ§Ã£o e ExecuÃ§Ã£o
Crie o ambiente virtual (Recomendado):

Bash

python -m venv venv
source venv/bin/activate
Instale as dependÃªncias:

Bash

pip install -r requirements.txt
Prepare o Ã¡udio: Certifique-se de que existe um arquivo chamado entrada.wav na raiz do projeto (vocÃª pode fazer upload de um Ã¡udio gravado ou gerar um para teste).

Execute o projeto:

Bash

python app.py
âš ï¸ Nota sobre Codespaces
Se vocÃª estiver rodando este cÃ³digo no GitHub Codespaces:

O script executarÃ¡ a transcriÃ§Ã£o e a geraÃ§Ã£o da resposta.

PorÃ©m, o Pygame nÃ£o conseguirÃ¡ reproduzir o som (pois o servidor na nuvem nÃ£o tem caixas de som).

O arquivo de resposta de Ã¡udio (ex: resposta.mp3) serÃ¡ salvo na pasta. VocÃª pode clicar com o botÃ£o direito no arquivo e escolher Download para ouvir o resultado.

ğŸ¯ Objetivo da Atividade
Este projeto foi desenvolvido como modelo didÃ¡tico para demonstrar:

IntegraÃ§Ã£o de APIs: ConexÃ£o entre serviÃ§os de IA e scripts locais.

SeguranÃ§a: Uso de variÃ¡veis de ambiente (.env) para proteger credenciais.

ModularizaÃ§Ã£o: SeparaÃ§Ã£o de responsabilidades (STT, LLM, TTS) em arquivos distintos.